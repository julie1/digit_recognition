# digit_recognition

This repository contains my work on a Udacity machine learning
project classifying digits appearing in various images.
Since I did a lot of experimentation with this project which for me was very time-consuming, I will present here an outline and where details can be found.

I started with a simple LSTM neural net adapted from https://github.com/aymericdamien/TensorFlow-Examples/ to classify individual digits from the notMIST and SVHN sets. I used a program from Alexander Yau 12/21/16 Stack Overflow to obtain bounding box information from the SVHN digitStruct.mat files which enabled me to obtain individual digits from the original photos. I calculated both the overall accuracy and that for sequences of 5 digits. The overall notMIST test accuracy was ~92% while the 5-sequence accuracy was ~67%. For the SVHN I obtained overall test accuracy ~85% but only ~46% for the 5-sequence accuracy. See digit_recognition.html for details.  

I then used a model based on a multilayer-percepton for the Udacity Deep Learning class which improved my results. The overall notMIST test accuracy was 94.5% while the 5-sequence accuracy was 75.2% For the SVHN data I obtained ~90% test accuracy and ~61% 5-sequence accuracy. I continued with this model for the photos sent to me by family members doing a fair amount of photo manipulation with cv2 including a graphical interface to obtain labels for individual digits. The overall accuracy was 93% and the 5-sequence accuracy was 75%. The cv2 did not localize the digits very well. See digit_recognition-Copy2.html for details.

I wanted to avoid convolution nets because the laptop that I had used has 2Gb RAM and frequently freezes for large data calculations. Step 4 using regression to find bounding boxes required me to pursue this approach (I briefly tried an adaptation of the multi-perceptron with poor results). The number plate recognition project of Matthew Earl https://matthewearl.github.io/2016/05/06/cnn-anpr/ and the Udacity digit recognition project of Brian Diesel https://github.com/bdiesel/tensorflow-svhn were very helpful, and I adapted their ideas and code. The stackoverflow http://stackoverflow.com/questions/34619177/what-does-tf-nn-conv2d-do-in-tensorflow had a good explanation of what exactly is computed in the 2D convolution.
I ran individual SVHN digits through a training run to classify digits and saved the weights and biases to use for the multidigit photos. I used Diesel's methods for cropping the multidigit photos. Using the original photos with large spaces on either side of the multidigits did not work well. The convolution net for classification resulted in a test accuracy of 92% for individual digits and 60% for multidigits. See Convolution_Net_for_Digits.html for details.

I then used the SVHN bounding box coordinates for training in the multidigit convolution net. The test accuracy of bounding box coordinates was 85% where I required each predicted bounding box to be within +- 5 pixels of the given SVHN bounding box. See Bounding_box_regression.html for details. I could not get more than 65% accuracy on training with single-digit images cut along the predicted bounding boxes. Since the accuracy for the bounding box regression does not improve to 80% until halfway through the training run, I excluded half of the digits obtained from the regression but could not substantially improve the result. See Box_classification_test.html for details. I then used the bounding box regression on photos taken by family members. The results were better than with cv2. See Boxes_for_my_images.html for details.

